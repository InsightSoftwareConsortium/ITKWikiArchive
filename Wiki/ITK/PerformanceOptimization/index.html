<!DOCTYPE html>

<html class="client-nojs" dir="ltr" lang="en">
<head>
<meta charset="utf-8"/>
<title>ITK/PerformanceOptimization</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"3956c203fb2aded6d2f4c4a8","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"ITK/PerformanceOptimization","wgTitle":"ITK/PerformanceOptimization","wgCurRevisionId":61905,"wgRevisionId":61905,"wgArticleId":14326,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":[],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"ITK/PerformanceOptimization","wgRelevantArticleId":14326,"wgIsProbablyEditable":!1,"wgRelevantPageIsProbablyEditable":!1,"wgRestrictionEdit":[],"wgRestrictionMove":[]};RLSTATE={"site.styles":"ready",
"noscript":"ready","user.styles":"ready","user":"ready","user.options":"loading","skins.monobook.styles":"ready"};RLPAGEMODULES=["site","mediawiki.page.ready","mediawiki.toc","skins.monobook.scripts"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link href="/Wiki/load.php?lang=en&amp;modules=skins.monobook.styles&amp;only=styles&amp;skin=monobook" rel="stylesheet"/>
<script async="" src="/Wiki/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=monobook"></script>
<meta content="" name="ResourceLoaderDynamicStyles"/>
<link href="/Wiki/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=monobook" rel="stylesheet"/>
<meta content="MediaWiki 1.37.1" name="generator"/>
<meta content="telephone=no" name="format-detection"/>
<meta content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=0.25, maximum-scale=5.0" name="viewport"/>
<link href="/favicon.ico" rel="shortcut icon"/>
<link href="/Wiki/opensearch_desc.php" rel="search" title="KitwarePublic (en)" type="application/opensearchdescription+xml"/>
<link href="https://public.kitware.com/Wiki/api.php?action=rsd" rel="EditURI" type="application/rsd+xml"/>
<link href="https://creativecommons.org/licenses/by/2.5/" rel="license"/>
<link href="/Wiki/index.php?title=Special:RecentChanges&amp;feed=atom" rel="alternate" title="KitwarePublic Atom feed" type="application/atom+xml"/>
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-ITK_PerformanceOptimization rootpage-ITK skin-monobook action-view skin--responsive"><!-- start content -->
<div class="mw-body-content mw-content-ltr" dir="ltr" id="mw-content-text" lang="en"><div class="mw-parser-output"><p>Recent performance improvements efforts:
</p>
<ul><li><a class="external text" href="http://review.source.kitware.com/#/c/22387/" rel="nofollow">itk::ThreadPool refactoring</a></li>
<li><a class="external text" href="http://review.source.kitware.com/#/c/22377/" rel="nofollow">Change itkMultiThreader to use OpenMP</a></li>
<li><a class="external text" href="http://www.insight-journal.org/browse/publication/974" rel="nofollow">ITK TBB Insight Journal article</a></li></ul>
<p><br/>
</p>
<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="en"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#ITK_Performance_Optimization_Meeting_Notes"><span class="tocnumber">1</span> <span class="toctext">ITK Performance Optimization Meeting Notes</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#2017-04-07"><span class="tocnumber">1.1</span> <span class="toctext">2017-04-07</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-3"><a href="#Performance_Analysis"><span class="tocnumber">2</span> <span class="toctext">Performance Analysis</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="#Per_Thread_Cost_of_Job_Dispatch"><span class="tocnumber">2.1</span> <span class="toctext">Per Thread Cost of Job Dispatch</span></a></li>
</ul>
</li>
</ul>
</div>
<h2><span class="mw-headline" id="ITK_Performance_Optimization_Meeting_Notes">ITK Performance Optimization Meeting Notes</span></h2>
<h3><span class="mw-headline" id="2017-04-07">2017-04-07</span></h3>
<p>Links:
</p>
<ul><li><a class="external text" href="http://www.insight-journal.org/browse/publication/974" rel="nofollow">TBB Insight Journal article</a></li>
<li><a class="external text" href="https://github.com/InsightSoftwareConsortium/ITKModuleTemplate" rel="nofollow">ITK Module Template</a></li>
<li><a class="external text" href="https://itk.org/ITKSoftwareGuide/html/Book1/ITKSoftwareGuide-Book1ch9.html#x48-1440009" rel="nofollow">ITK Module Documentation</a></li>
<li><a class="external text" href="https://github.com/hjmjohnson/tbb" rel="nofollow">CMake'ified TBB</a></li>
<li><a class="external text" href="https://blog.kitware.com/simple-parallel-computing-with-vtksmptools-2/" rel="nofollow">VTK SMPTools</a></li>
<li><a class="external text" href="https://itk.org/Doxygen/html/classitk_1_1ImageScanlineIterator.html" rel="nofollow">itkScanlineIterator</a></li>
<li><a class="external text" href="https://itk.org/Doxygen/html/classitk_1_1ForwardFFTImageFilter.html" rel="nofollow">ITK FFT classes</a></li></ul>
<p>Possible next steps:
</p>
<ul><li>TBB Insight Journal update</li>
<li>TBB Insight Journal -&gt; Remote Module</li>
<li>Improved compiler optimization flags</li>
<li>MKL backend for FFT</li>
<li>CMake-ified TBB upstreaming / available as an ITK module</li>
<li>Improved awareness of ImageScanlineIterator</li></ul>
<p><br/>
</p>
<h2><span class="mw-headline" id="Performance_Analysis">Performance Analysis</span></h2>
<h3><span class="mw-headline" id="Per_Thread_Cost_of_Job_Dispatch">Per Thread Cost of Job Dispatch</span></h3>
<p>An important metric in analyzing the scalability of multi-threading algorithms is the knowing the cost to spawn or use additional thread for a task. Knowing the cost allows an estimate of the expected improvement additional thread can potentially achieve for a perfectly scale able algorithm. It can also provide an estimate of the threading over for example if you are running X filters per second with N threads, then you can compute the time spent with threading over head. The can help determine if the expected improvement from improving the threading model vs improving the algorithms.
</p><p>The overhead for spawning threads is computed by measuring the time it takes the `AddImageFilter` to run with 1 thread on 1 pixel, and the time it takes to run with N threads on N pixels. Each thread does the one pixel trivial operation. The difference in execution time is considered the overhead for spawning the threads. Dividing by the number of additional threads gives us the overhead cost of “spawning” or dispatching. To estimate the cost the following SimpleITK code was initially used:
</p>
<pre> def compute_thread_cost(n):
     sitk.ProcessObject_SetGlobalDefaultNumberOfThreads(1)
     img = sitk.Image(1,1, sitk.sitkFloat32)
     t1 = min(timeit.repeat( lambda img=img: sitk.Add(img,img), number=1,repeat=25))
     sitk.ProcessObject_SetGlobalDefaultNumberOfThreads(n)
     img = sitk.Image(1,n, sitk.sitkFloat32)
     t2 = min(timeit.repeat( lambda img=img: sitk.Add(img,img), number=1,repeat=25))
     print( "1 Thread: {0}\n{1} Threads: {2}".format(t1,n,t2))
     cost=(t2-t1)/(n-1.0)
     print("Cost per thread: {0}".format(cost))
</pre>
<p>SimpleITK was recompiled with the Default ITK, the <a class="external text" href="http://review.source.kitware.com/#/c/22387/5" rel="nofollow">rewritten-thread-pool</a>, and <a class="external text" href="http://review.source.kitware.com/#/c/22377/1" rel="nofollow">TheReturnOfOpenMP</a>.
</p><p>The following results were with the following system:
</p>
<pre>Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                88
On-line CPU(s) list:   0-87
Thread(s) per core:    2
Core(s) per socket:    22
Socket(s):             2
NUMA node(s):          2
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 79
Model name:            Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz
Stepping:              1
CPU MHz:               2800.617
BogoMIPS:              4410.78
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              56320K
NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86
NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87
</pre>
<p>Here are the results.
</p><p>Default ITK:
</p>
<pre>&gt;compute_thread_cost(88)
1 Thread: 7.9870223999e-05
88 Threads: 0.00240182876587
Cost per thread: 2.66891786422e-05 (seconds)
</pre>
<p>rewriting-thread-pool:
</p>
<pre>&gt;compute_thread_cost(88)
1 Thread: 7.60555267334e-05
88 Threads: 0.000521183013916
Cost per thread: 5.11640789865e-06 (seconds)
</pre>
<p>TheReturnOfOpenMP:
</p>
<pre>&gt;compute_thread_cost(88)
1 Thread: 7.79628753662e-05
88 Threads: 0.000182867050171
Cost per thread: 1.2057951127e-06 (seconds)
</pre>
<p><br/>
To summarize these results: the rewriting-thread-pool topic has a 5.2X speed up for spawning thread, and the TheReturnOfOpenMP topic as a 22X speedup. 
</p><p>Re-running the test code has a bit (~20% with occasional outlier) of variability. The results are quite similar with spawning a smaller number of threads. So this type of testing can be done on a smaller system too.
</p><p>So if you are using 100 filters per second with 100 threads each, the thread overhead will take 1% to 26% of the time. That is a lot of filters and threads to encounter this potential bottle neck, however we need to know the current usage and expectation for the number of filters and threads to run per second.
</p>
<!-- 
NewPP limit report
Cached time: 20230129154427
Cache expiry: 86400
Reduced expiry: false
Complications: []
CPU time usage: 0.006 seconds
Real time usage: 0.007 seconds
Preprocessor visited node count: 12/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 0/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->
<!-- Saved in parser cache with key KitwarePublicWikiDB:pcache:idhash:14326-0!canonical and timestamp 20230129154427 and revision id 61905. Serialized with JSON.
 -->
</div>
</div>

<!-- end content --></body></html>